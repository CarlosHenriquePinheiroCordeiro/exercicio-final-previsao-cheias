{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Final Optativa I - Tópicos Especiais de Informática (Ciências de Dados)\n",
    "Aluno: Carlos Henrique Pinheiro Cordeiro\n",
    "\n",
    "Este trabalho tem como objetivo exercitar os conceitos práticos que envoltam a Ciência de Dados, aplicando métodos que um cientista de dados pratica no seu dia a dia, como a análise do contexto que se procura uma resposta para uma dada pergunta, a captura dos dados, a limpeza destes mesmos dados, e por fim o uso das tecnologias necessárias para atingir seu objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Abertura e limpeza dos dados\n",
    "\n",
    "Primeiramente é necessário abrir os arquivos contendo os dados necessários para a resolução do exercício. Os arquivos contendo os dados referentes à quantidade de chuva  (mm) e o nível da água (cm), foram renomeados para serem mais simples de abrir e identificar quais destes contém o necessário para o dado momento. Receberam nomes com prefixo que anuncia qual dado está presente, se é chuva ou nível, seguido do nome da cidade do qual foram obtidos estes dados. Por exemplo: \"chuva-taio.txt\" contempla os dados dos níveis de chuva da cidade de Taió.\n",
    "\n",
    "Os arquivos foram abertos e salvos em variáveis de \"dataset\", para depois estes datasets passarem por processos de limpeza dos seus dados, sendo preparados para o treinamento do modelo que nos fará atingir nosso objetivo, que será abordado na próxima seção.\n",
    "\n",
    "De longe, esta foi a parte mais difícil de se realizar e planejar. A questão era pensar como os arquivos seriam limpos de modo que seja fácil de abri-los como DataSets pelo Pandas. Com o auxílio do software VSCode e suas ferramentas (nativas) de substituição de caracteres, foi possível tratar os arquivos de txt como se fossem csv's (comma separated values - valores separados por vírgula). Sendo assim, bastou apenas abrir os arquivos por aqui pelo Pandas, e tratar as colunas de cada um. Após, o desafio foi planejar como estes dados poderiam ser unidos e \"conversariam\". Para tal, foi decidido juntar os DataSets através de um \"merge\" pela Data e Hora, em um DataSet geral. Bastando que depois apenas fosse realizado um tratamento final de valores nulos e reinicialização de índice do DataSet, para uma melhor leitura de seus dados. Sendo assim, estamos prontos para o próximo passo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Implementação da Abertura e Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Função para abrir um arquivo de txt com os dados, apenas informando de qual cidade quero o arquivo\n",
    "def abreArquivoNivel(cidade):\n",
    "    nomeArquivo = 'nivel-'+cidade+'.txt'\n",
    "    df = pd.read_csv(nomeArquivo, sep=\",\", encoding=\"UTF-8\", names=[cidade+'-un1', 'data', 'hora', cidade+'Nivel', cidade+'-un2'])\n",
    "    df = df.drop(columns=[cidade+'-un1', cidade+'-un2'])\n",
    "    return df\n",
    "\n",
    "#Abertura dos arquivos por cidade\n",
    "nivelTaio       = abreArquivoNivel(\"taio\")\n",
    "nivelRioDoSul   = abreArquivoNivel(\"riodosul\")\n",
    "nivelItuporanga = abreArquivoNivel(\"ituporanga\")\n",
    "\n",
    "#Criação do DataSet geral\n",
    "dadosGerais = pd.merge(nivelRioDoSul, nivelTaio      , how='left', on=['data', 'hora'])\n",
    "dadosGerais = pd.merge(dadosGerais  , nivelItuporanga, how='left', on=['data', 'hora'])\n",
    "dadosGerais = dadosGerais.dropna()\n",
    "dadosGerais = dadosGerais.reset_index()\n",
    "dadosGerais = dadosGerais.drop(columns='index')\n",
    "print(dadosGerais)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Formulação do objetivo\n",
    "\n",
    "Tendo em mãos os dados, já limpos, das chuvas e níveis das cidades de Rio do Sul, Ituporanga e Taió, sendo os valores correspondendes à Data, Hora e a respectiva medida, podemos estabelecer um objetivo para alcançar, a partir destes dados utilizados no treinamento de algum modelo de Aprendizado de Máquina.\n",
    "\n",
    "O objetivo é treinar um modelo de aprendizado de máquina que possa nos dar uma previsão do nível do rio de Rio do Sul, de acordo com o nível dos rios de Ituporanga e Taió. Sendo assim, daremos a ele o nível dos rios de Ituporanga e Taió, e ele nos dará qual será o nível do rio de Rio do Sul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Montagem do DataSet para treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Montagem dos dados para treinamento\n",
    "x = dadosGerais[['taioNivel', 'ituporangaNivel']]\n",
    "y = dadosGerais['riodosulNivel']\n",
    "\n",
    "#Separando o conjunto de dados em um conjunto para treinamento e outro para testes\n",
    "xTreinamento, xTeste, yTreinamento, yTeste = train_test_split(x, y, train_size = 0.8, test_size = 0.2)\n",
    "\n",
    "#Treinamento do modelo com os dados\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(xTreinamento, yTreinamento)\n",
    "\n",
    "#Previsão\n",
    "previsaoCheia = modelo.predict(xTeste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Métricas de erro do modelo\n",
    "\n",
    "Passada uma previsão de cheia dando os níveis de Taió e Ituporanga, temos as métricas de erro relacionadas ao modelo, observando por aqui: R-Quadrado, R-Quadrado Ajustado, Erro Quadrático Médio ou MSE (por mais que tenha suas desvantagens, como veremos na diferença dos resultados deste para os do RMSE), Raíz do Erro Quadrático Médio (RMSE), Erro Percentual Absoluto Médio (MAPE), e por último, uma tabela de correlação por cores.\n",
    "\n",
    "Assim, finalizando o trabalho, empregando o uso das tecnologias apropriadas junto das técnicas e práticas exercidas, sendo esta mistura ensinada em sala de aula, assim exercendo um estudo e exercício pragmático da Ciência de Dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "#R²\n",
    "R2 = r2_score(yTeste, previsaoCheia)\n",
    "print('R²: ',R2)\n",
    "\n",
    "#R² Ajustado\n",
    "R2Ajustado = (1 - ((1 - r2_score(yTeste, previsaoCheia)) * (len(yTeste) - 1)) / \n",
    "            (len(yTeste) - xTeste.shape[1] - 1))\n",
    "print('R² Ajustado: ', R2Ajustado)\n",
    "\n",
    "#Erro Quadrático Médio (MSE)\n",
    "MSE = mean_squared_error(yTeste, previsaoCheia)\n",
    "print(\"Erro Quadrático Médio: %.2f\" %MSE)\n",
    "\n",
    "#Raíz do Erro Quadrático Médio (RMSE)\n",
    "RMSE = mean_squared_error(yTeste, previsaoCheia, squared=False) \n",
    "print(\"Raíz do Erro Quadrático Médio: %.2f\" %RMSE)\n",
    "\n",
    "#Erro Percentual Absoluto Médio (MAPE)\n",
    "MAPE = np.mean(np.abs((yTeste - previsaoCheia) / yTeste)) * 100\n",
    "print(\"Erro Percentual Absoluto Médio: %.2f\" %MAPE+\"%\")\n",
    "\n",
    "#Tabela de Correlação por Cores\n",
    "tabela = dadosGerais.corr()\n",
    "tabela.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
